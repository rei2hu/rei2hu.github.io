<!-- markdownlint-disable -->

# Compound Words

I thought of this problem after I encountered a simpler version of it
_somewhere_. I'll present the easier version first and then give the generalized
(harder) problem.

## Simple version

<p>

Given a list of words, return a list of lists which contain words that can be
combined to make another word in the list. <br /> <br /> More specifically,
given an array $words$, find all pairs of $words[i]$ and $words[j]$ where
$words[i] + words[j] = words[k]$. <br /> <br /> And to keep thing simple, we
allow using the same word multiple times e.g. allowing $words[i] + words[i]$ and
no empty string: $words[i] \neq \text{ ""}$ <br /> <br /> There are several
solutions with varying efficienies

</p>

1. Three nested loops over $i$, $j$, and $k$ which are the length of $words$
   where we check if $words[i] = words[j] + words[k]$.
2. Two nested loops over $i$ and $j$ which are the length of $words$ where we
   check if $words[i]$ starts with (or ends with) $words[j]$ and if
   $words[i] - words[j]$ is in $words$.
3. One loop over $i$ (the length of $words$) and an inner loop over $j$, the
   length of $words[i]$ (!) and seeing if $words[i][0\ldots j]$ and
   $words[i][j\ldots len(words[i])]$ are both in $words$.

<p>
How efficient is each solution? The first one is straightforward to evaluate as $O(n^3)$
due to three loops. In our following cases, we'll use $n$ as the length of the list.
<br />
<br />
The second and third are more interesting, as checking if an element is in a list
can be reduced to a possibly faster implementation via hashing. However, it's important
to note that the runtime for hashing a string is respective to its length! So let's
call this $O(m)$ to perform the hash and lookup. Therefore solution 2 is $O(n^2m)$
and solution 3 is $O(nm^2)$.
<br />
<br />
I assume some people would treat $m$ as a constant because it's not related to the
input, however specifically because the question is about compound words i.e. a
word is made up of other words, this suggests that $m_i = m_j + m_k$ for some
$i$, $j$, and $k$ which means that $m$ really has no fixed bounds unless explicitly
stated - if you have a word with length $m_j$ then there could be a word with length
$m_j + m_k$.

Either way, we can see that (3) probably is probably going to perform the best
if your words aren't longer than the list. I'm not interested in benchmarks
here.

</p>

## Generalized version

<p>
The generalized version is just to put together all possible combinations, so we
no longer care about pairs. It should be straightforward to extend some of our previous
solutions for this, so let's do that and look at the performances.
<br />
<br />
(1) We have our outer loop $i$, and then $n$ inner loops to generate every single
combination $words[n_1] + words[n_2] + \ldots + words[n_n]$ and seeing if it equals
$words[i]$. This is $O(n^n)$
<br />
<br />
(2) Unfortunately, checking for membership of $words[i] - words[j]$ may not work
here as it may still be made up of multiple words, so it's not straightforward to
port. What we should keep in mind is the "starts with" idea.
<br />
<br />
(3) We maintain our outer loop $i$ and split $words[i]$ until we find a prefix that
is in $words$, then we have to split $words[i] - prefix$ and doing the same thing
until we run out of places to split. In other words, how many ways can you break
up $words[i]$? into $1\ldots m$ pieces? You can break up $words[i]$ into $j$ pieces
$len(words[i]) \text{ choose } j$ ways, which means the total ways you can break
up $words[i]$ will be $\sum_{j=1}^{m}{\frac{m!}{j!(m-j)!}}$ and for each possible
combination, we have to hash $j$ times. Admittedly, this gets too complex for me
to casually evaluate so let's say it's $O(m * m! * m)$ which should be a valid but
non-tight upper bound. And with the other loop $O(nm^2m!)$. And because $m!$ grows
faster than $m^2$ we can simplify to $O(nm!)$.
<br />
<br />
And then comes my other idea. Remember the "starts with" idea? Originally, I was
thinking of bucketing words that start with the same words together in a sort of
bucket sort because if words don't start with the same letters than it's a case for
early termination but it was too fuzzy to evaluate. The simpler approach is to use
a trie.
<br />
<br />
Generating a trie is $O(nm)$ and walking through the trie is $O(nm)$ but what do
we do as we walk through the trie? As we come across $words[i]$ in the trie, we then
then search for $words[j] - words[i]$ where $words[j]$ is a word further down the
current path of the trie and do that until we hit the end of the trie or run out
of things to match against. What's the runtime? Well, we have $O(nm)$ for going
through the trie, then we may have at most $n$ possible words down a branch, and
we will traverse at most $m$ nodes for each of those, but then we may come across
another $n$ words down the newer branch. I really don't know. Let's just say
$O(n!m^2)$ and call it a day.
<br />
<br />
There are definitely some other ideas out there, like a combination of building
every possible string up to length $m$ or sorting by string length or taking advantage
of the length somehow, but who knows. I think 1 hour is enough time spent thinking
about this.
<br />
<br />
Hmm, not the best post for the exercises section; originally I wanted these to be
solid but maybe incorrect solutions to problems but I guess not anymore.
</p>
