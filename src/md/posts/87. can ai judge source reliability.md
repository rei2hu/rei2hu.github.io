# can ai judge source reliability

I feel like I'm doing the world a disservice by saying AI but talking about
LLMs. And of course mentioning LLMs when talking about Bing Chat.

I've always been apprehensive about the accuracy of LLMs, though I have started
using Bing Chat when my normal searches turn up nothing. The main benefit of
Bing Chat over ChatGPT is that it aims to cite sources, but may not always do
so.

Recently, a friend showed me
[this article](https://xyvir.medium.com/dreamworks-set-to-adapt-skibidi-toilet-into-feature-length-movie-823810a1995d)
that claims that there's a Skibidi Toilet movie coming out (I never thought I'd
be writing about it but here I am). But quick further investigation shows that
this is a joke article, and that the author is a satirist - they have articles
such as:

- [NIST Reports 99.9% of Internet Users Keep All Their Passwords in a Public-Facing, SEO-Optimized Tumblr Post](https://xyvir.medium.com/nist-reports-99-9-7e98d7fc9cfd)
- [Climatologists Switch To Destroying The Earth As Quickly As Possible, Say It's Far More Ethical](https://xyvir.medium.com/climatologists-switch-to-destroying-the-earth-as-quickly-as-possible-say-its-far-more-ethical-8221aa44b623)
- [Department of Homeland Security Says “AI Disinformation Mills Kinda Cool, Actually”](https://xyvir.medium.com/department-of-homeland-security-says-ai-disinformation-mills-kinda-cool-actually-004ef1542357)

However, what I noticed is that this article is one of the top results when
searching for the existence or plan for a Skibidi Toilet movie. Would Bing Chat
cite this source and say there is actually a movie in the works?

![bing chat citing fandom and saying there's a
movie](/blobs/87/skibidimovie.png)

What are some of these sources?

- A
    [page from an ideas fandom wiki](https://ideas.fandom.com/wiki/Skibidi_Toilet:_The_Movie)
    aka fantasy
- A
    [video claiming to be the trailer for a Netflix movie](https://www.youtube.com/watch?v=KgRipuWDp8s)
    that doesn't belong to the Netflix channel
- An [imdb link](https://www.imdb.com/title/tt27814427/) for the actual series
    itself

So they're all bogus when it comes to information about a real movie. At least
it didn't cite the Medium article, though I'm sure it would have if it could.
Does it know that the main citations that it's getting its information from are
not real? Why not ask if the sources are reliable:

![yes my sources are reliable](/blobs/87/reliablesources.png)

Seems like they are! But obviously they're not.

I'm not really interested in prompting it more because I believe the supposed
value-add of these LLMs should be correct answers, and having to guide it along
and double check its work contradicts that.

So, at the end of the day, I just use Bing Chat as a way to find sources rather
than rely on its generated summary, and only use it once normal searching turns
up nothing. I've experienced moments where it said the right things and provided
sources, times when it pulled the correct sources and said the wrong thing,
times when it provided no sources and said the right thing (after figuring it
out and confirming for myself), and I've experienced times when it referenced
inaccurate sources and said the wrong thing, like now.

You could argue the value of an LLM is there, but I would say it's a lot less
impressive than what is being marketed.

And I can't write an AI post now without saying something about the OpenAI
implosion that started last Friday, but I find it interesting to follow; less so
because it will carve out the path of future AI development, but more so about
how large companies approach these kinds of events.

These questions were asked as late as November 20, 2023 using bing chat's
precision mode.
